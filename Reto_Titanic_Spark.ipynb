{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importación de librerías\n"
      ],
      "metadata": {
        "id": "46ZMGOg2HA6a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyiVDvVMnuEv",
        "outputId": "3117c623-893f-4faf-fe8f-0a5467eab694"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.91.82)] [Connecting to security.ub\u001b[0m\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Ign:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy Release\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "51 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "tar: spark-3.2.1-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.2)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#Check this site for the latest download link https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j\n",
        "\n",
        "import os\n",
        "import sys\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SQLContext\n",
        "# Check if a SparkContext already exists\n",
        "if not 'sc' in globals():\n",
        "  sc = SparkContext()\n",
        "else:\n",
        "  print(\"Using existing SparkContext\")\n",
        "\n",
        "sqlContext = SQLContext(sc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qw8Zd5jVnyYN",
        "outputId": "b0adc76e-68bb-4e12-d0d3-48169c919c8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using existing SparkContext\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocesamiento de los datos"
      ],
      "metadata": {
        "id": "JM8jOuF8HK4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bd = sqlContext.read.format(\"com.databricks.spark.csv\"\n",
        ").option(\"header\", \"true\"\n",
        ").option(\"inferSchema\", \"true\"\n",
        ").load(\"train.csv\")"
      ],
      "metadata": {
        "id": "nSlQv27in0li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bd.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WomtRTewpFOi",
        "outputId": "e1f92e70-e3f4-47e4-f967-2303fc09129f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|\n",
            "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
            "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
            "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
            "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|\n",
            "|          6|       0|     3|    Moran, Mr. James|  male|NULL|    0|    0|          330877| 8.4583| NULL|       Q|\n",
            "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
            "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| NULL|       S|\n",
            "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| NULL|       S|\n",
            "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| NULL|       C|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checar valores nulos en los registros\n"
      ],
      "metadata": {
        "id": "cSHnxwC9H66k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, isnan, when, count\n",
        "\n",
        "bd.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in bd.columns]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkKTxlGdIEDG",
        "outputId": "909fbc69-1d06-43ff-bbae-1fe97c954a62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
            "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
            "|          0|       0|     0|   0|  0|177|    0|    0|     0|   0|  687|       2|\n",
            "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imputación de datos faltantes en age"
      ],
      "metadata": {
        "id": "zTyp5w72IVpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, regexp_extract, when, lit, randn\n",
        "from pyspark.sql.types import IntegerType\n",
        "import numpy as np\n",
        "from pyspark.sql.functions import mean, stddev, udf\n",
        "import random\n",
        "from pyspark.sql.types import DoubleType\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "titles = ['Mr', 'Mrs', 'Master', 'Miss']\n",
        "\n",
        "for passenger in bd:\n",
        "    title = regexp_extract(col(\"Name\"), r\"([A-Za-z]+)\\.\", 1)\n",
        "    bd = bd.withColumn(\"Title\", when(title.isin(titles), title).otherwise(lit(\"Other\")))\n",
        "\n",
        "\n",
        "titles_count = bd.groupBy('Title').count()\n",
        "print(titles_count.show())\n",
        "\n",
        "age_stats = bd.groupBy('Title').agg(mean('Age').alias(\"mean_age\"), stddev('Age').alias(\"stddev_age\"))\n",
        "\n",
        "\n",
        "bd = bd.join(age_stats, on=\"Title\", how=\"left\")\n",
        "\n",
        "# Rellena los valores nulos en la columna \"Age\" con una distribución normal\n",
        "bd = bd.withColumn(\n",
        "    \"Age\",\n",
        "    when(col(\"Age\").isNull(), col(\"mean_age\") + col(\"stddev_age\") * randn())  # Genera un valor aleatorio basado en la media y desviación estándar\n",
        "    .otherwise(col(\"Age\"))\n",
        ")\n",
        "\n",
        "#Rellenar datos nulos con la media\n",
        "mean_age = bd.select(mean('Age')).collect()[0][0]\n",
        "bd = bd.na.fill(mean_age, subset=[\"Age\"])\n",
        "\n",
        "#Eliminar columnas adicionales\n",
        "bd = bd.drop(\"mean_age\", \"stddev_age\")\n",
        "\n",
        "# Muestra el DataFrame transformado\n",
        "bd.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9p9qiiayv5S",
        "outputId": "f89423a2-daff-4550-d913-ff3145829d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "| Title|count|\n",
            "+------+-----+\n",
            "|  Miss|  182|\n",
            "| Other|   27|\n",
            "|Master|   40|\n",
            "|    Mr|  517|\n",
            "|   Mrs|  125|\n",
            "+------+-----+\n",
            "\n",
            "None\n",
            "+------+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+-----+--------+\n",
            "| Title|PassengerId|Survived|Pclass|                Name|   Sex|               Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
            "+------+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+-----+--------+\n",
            "|    Mr|          1|       0|     3|Braund, Mr. Owen ...|  male|              22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|\n",
            "|   Mrs|          2|       1|     1|Cumings, Mrs. Joh...|female|              38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
            "|  Miss|          3|       1|     3|Heikkinen, Miss. ...|female|              26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
            "|   Mrs|          4|       1|     1|Futrelle, Mrs. Ja...|female|              35.0|    1|    0|          113803|   53.1| C123|       S|\n",
            "|    Mr|          5|       0|     3|Allen, Mr. Willia...|  male|              35.0|    0|    0|          373450|   8.05| NULL|       S|\n",
            "|    Mr|          6|       0|     3|    Moran, Mr. James|  male| 16.45524014813838|    0|    0|          330877| 8.4583| NULL|       Q|\n",
            "|    Mr|          7|       0|     1|McCarthy, Mr. Tim...|  male|              54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
            "|Master|          8|       0|     3|Palsson, Master. ...|  male|               2.0|    3|    1|          349909| 21.075| NULL|       S|\n",
            "|   Mrs|          9|       1|     3|Johnson, Mrs. Osc...|female|              27.0|    0|    2|          347742|11.1333| NULL|       S|\n",
            "|   Mrs|         10|       1|     2|Nasser, Mrs. Nich...|female|              14.0|    1|    0|          237736|30.0708| NULL|       C|\n",
            "|  Miss|         11|       1|     3|Sandstrom, Miss. ...|female|               4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
            "|  Miss|         12|       1|     1|Bonnell, Miss. El...|female|              58.0|    0|    0|          113783|  26.55| C103|       S|\n",
            "|    Mr|         13|       0|     3|Saundercock, Mr. ...|  male|              20.0|    0|    0|       A/5. 2151|   8.05| NULL|       S|\n",
            "|    Mr|         14|       0|     3|Andersson, Mr. An...|  male|              39.0|    1|    5|          347082| 31.275| NULL|       S|\n",
            "|  Miss|         15|       0|     3|Vestrom, Miss. Hu...|female|              14.0|    0|    0|          350406| 7.8542| NULL|       S|\n",
            "|   Mrs|         16|       1|     2|Hewlett, Mrs. (Ma...|female|              55.0|    0|    0|          248706|   16.0| NULL|       S|\n",
            "|Master|         17|       0|     3|Rice, Master. Eugene|  male|               2.0|    4|    1|          382652| 29.125| NULL|       Q|\n",
            "|    Mr|         18|       1|     2|Williams, Mr. Cha...|  male| 24.16033931325555|    0|    0|          244373|   13.0| NULL|       S|\n",
            "|   Mrs|         19|       0|     3|Vander Planke, Mr...|female|              31.0|    1|    0|          345763|   18.0| NULL|       S|\n",
            "|   Mrs|         20|       1|     3|Masselmani, Mrs. ...|female|24.335531990099774|    0|    0|            2649|  7.225| NULL|       C|\n",
            "+------+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+-----+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Codificación de la variable Sex"
      ],
      "metadata": {
        "id": "1asMPBaRVHQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "# Define el indexador para la columna 'Sex'\n",
        "indexer = StringIndexer(inputCol=\"Sex\", outputCol=\"SexIndex\")\n",
        "\n",
        "# Ajusta el indexador a los datos y transforma el DataFrame\n",
        "bd = indexer.fit(bd).transform(bd)\n",
        "\n",
        "bd.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXviL7iew4PB",
        "outputId": "1b6dfde8-64a3-472f-bff9-2a2714621f14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+--------+\n",
            "|Title|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|SexIndex|\n",
            "+-----+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+--------+\n",
            "|   Mr|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|     0.0|\n",
            "|  Mrs|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|     1.0|\n",
            "| Miss|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|     1.0|\n",
            "|  Mrs|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|     1.0|\n",
            "|   Mr|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|     0.0|\n",
            "+-----+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Codificación de la variable embarked"
      ],
      "metadata": {
        "id": "ppMG7LmIVo6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rellenar valores faltantes en la columna 'Embarked' con el valor más frecuente\n",
        "mode_value = bd.groupBy(\"Embarked\").count().orderBy(\"count\", ascending=False).first()[0]\n",
        "bd = bd.na.fill({\"Embarked\": mode_value})\n",
        "\n",
        "# Reemplazar valores en la columna 'Embarked'\n",
        "bd = bd.withColumn(\n",
        "    \"Embarked\",\n",
        "    when(col(\"Embarked\") == 'S', 1)\n",
        "    .when(col(\"Embarked\") == 'C', 2)\n",
        "    .when(col(\"Embarked\") == 'Q', 3)\n",
        "    .otherwise(col(\"Embarked\"))\n",
        ")\n",
        "\n",
        "# Muestra el DataFrame transformado\n",
        "bd.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-WLSoOVx8GH",
        "outputId": "ef29e9c9-2495-4fef-9464-5d442c51333f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+-----+--------+--------+\n",
            "| Title|PassengerId|Survived|Pclass|                Name|   Sex|               Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|SexIndex|\n",
            "+------+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+-----+--------+--------+\n",
            "|    Mr|          1|       0|     3|Braund, Mr. Owen ...|  male|              22.0|    1|    0|       A/5 21171|   7.25| NULL|       1|     0.0|\n",
            "|   Mrs|          2|       1|     1|Cumings, Mrs. Joh...|female|              38.0|    1|    0|        PC 17599|71.2833|  C85|       2|     1.0|\n",
            "|  Miss|          3|       1|     3|Heikkinen, Miss. ...|female|              26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       1|     1.0|\n",
            "|   Mrs|          4|       1|     1|Futrelle, Mrs. Ja...|female|              35.0|    1|    0|          113803|   53.1| C123|       1|     1.0|\n",
            "|    Mr|          5|       0|     3|Allen, Mr. Willia...|  male|              35.0|    0|    0|          373450|   8.05| NULL|       1|     0.0|\n",
            "|    Mr|          6|       0|     3|    Moran, Mr. James|  male| 16.45524014813838|    0|    0|          330877| 8.4583| NULL|       3|     0.0|\n",
            "|    Mr|          7|       0|     1|McCarthy, Mr. Tim...|  male|              54.0|    0|    0|           17463|51.8625|  E46|       1|     0.0|\n",
            "|Master|          8|       0|     3|Palsson, Master. ...|  male|               2.0|    3|    1|          349909| 21.075| NULL|       1|     0.0|\n",
            "|   Mrs|          9|       1|     3|Johnson, Mrs. Osc...|female|              27.0|    0|    2|          347742|11.1333| NULL|       1|     1.0|\n",
            "|   Mrs|         10|       1|     2|Nasser, Mrs. Nich...|female|              14.0|    1|    0|          237736|30.0708| NULL|       2|     1.0|\n",
            "|  Miss|         11|       1|     3|Sandstrom, Miss. ...|female|               4.0|    1|    1|         PP 9549|   16.7|   G6|       1|     1.0|\n",
            "|  Miss|         12|       1|     1|Bonnell, Miss. El...|female|              58.0|    0|    0|          113783|  26.55| C103|       1|     1.0|\n",
            "|    Mr|         13|       0|     3|Saundercock, Mr. ...|  male|              20.0|    0|    0|       A/5. 2151|   8.05| NULL|       1|     0.0|\n",
            "|    Mr|         14|       0|     3|Andersson, Mr. An...|  male|              39.0|    1|    5|          347082| 31.275| NULL|       1|     0.0|\n",
            "|  Miss|         15|       0|     3|Vestrom, Miss. Hu...|female|              14.0|    0|    0|          350406| 7.8542| NULL|       1|     1.0|\n",
            "|   Mrs|         16|       1|     2|Hewlett, Mrs. (Ma...|female|              55.0|    0|    0|          248706|   16.0| NULL|       1|     1.0|\n",
            "|Master|         17|       0|     3|Rice, Master. Eugene|  male|               2.0|    4|    1|          382652| 29.125| NULL|       3|     0.0|\n",
            "|    Mr|         18|       1|     2|Williams, Mr. Cha...|  male| 24.16033931325555|    0|    0|          244373|   13.0| NULL|       1|     0.0|\n",
            "|   Mrs|         19|       0|     3|Vander Planke, Mr...|female|              31.0|    1|    0|          345763|   18.0| NULL|       1|     1.0|\n",
            "|   Mrs|         20|       1|     3|Masselmani, Mrs. ...|female|24.335531990099774|    0|    0|            2649|  7.225| NULL|       2|     1.0|\n",
            "+------+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+-----+--------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eliminación de columnas innecesarias"
      ],
      "metadata": {
        "id": "vGMCGAcNVvA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bd = bd.drop(\"Name\", \"Ticket\", \"Cabin\", \"Embarked\", \"Sex\", \"Title\", \"Age\", \"SibSp\", \"Parch\")\n",
        "bd.show(5)\n"
      ],
      "metadata": {
        "id": "vvVC4PK0psgw",
        "outputId": "1af59bfe-a29c-46f8-d29e-68d5cf3ce305",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+-------+--------+\n",
            "|PassengerId|Survived|Pclass|   Fare|SexIndex|\n",
            "+-----------+--------+------+-------+--------+\n",
            "|          1|       0|     3|   7.25|     0.0|\n",
            "|          2|       1|     1|71.2833|     1.0|\n",
            "|          3|       1|     3|  7.925|     1.0|\n",
            "|          4|       1|     1|   53.1|     1.0|\n",
            "|          5|       0|     3|   8.05|     0.0|\n",
            "+-----------+--------+------+-------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalización de datos"
      ],
      "metadata": {
        "id": "ZANBAF4XcJ50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import MinMaxScaler\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "# UDF for converting column type from vector to double type\n",
        "unlist = udf(lambda x: round(float(list(x)[0]),3), DoubleType())\n",
        "\n",
        "\n",
        "for i in [\"Fare\",\"Pclass\"]:\n",
        "\n",
        "    assembler = VectorAssembler(inputCols=[i],outputCol=i+\"_Vect\")\n",
        "\n",
        "\n",
        "    scaler = MinMaxScaler(inputCol=i+\"_Vect\", outputCol=i+\"_Scaled\")\n",
        "\n",
        "\n",
        "    pipeline = Pipeline(stages=[assembler, scaler])\n",
        "\n",
        "\n",
        "    bd = pipeline.fit(bd).transform(bd).withColumn(i+\"_Scaled\", unlist(i+\"_Scaled\")).drop(i+\"_Vect\")\n",
        "\n",
        "bd = bd.drop(\"Fare\",\"Pclass\")\n",
        "print(\"After Scaling :\")\n",
        "bd.show(5)"
      ],
      "metadata": {
        "id": "t4Q9PXQXcNna",
        "outputId": "8f8bc8b4-16fb-48be-fc51-6e1805e34198",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Scaling :\n",
            "+-----------+--------+--------+-----------+-------------+\n",
            "|PassengerId|Survived|SexIndex|Fare_Scaled|Pclass_Scaled|\n",
            "+-----------+--------+--------+-----------+-------------+\n",
            "|          1|       0|     0.0|      0.014|          1.0|\n",
            "|          2|       1|     1.0|      0.139|          0.0|\n",
            "|          3|       1|     1.0|      0.015|          1.0|\n",
            "|          4|       1|     1.0|      0.104|          0.0|\n",
            "|          5|       0|     0.0|      0.016|          1.0|\n",
            "+-----------+--------+--------+-----------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entramiento de modelos"
      ],
      "metadata": {
        "id": "3zIuzk-SHYr-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "E3FPMtJbwHeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Divide el DataFrame completo en entrenamiento y prueba\n",
        "train_data, test_data = bd.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Divide el DataFrame de entrenamiento y prueba en X y Y\n",
        "X_train = train_data.drop(\"Survived\")\n",
        "Y_train = train_data.select(\"PassengerId\", \"Survived\")\n",
        "\n",
        "X_test = test_data.drop(\"Survived\")\n",
        "Y_test = test_data.select(\"PassengerId\", \"Survived\")\n",
        "\n",
        "# Unir los conjuntos de entrenamiento\n",
        "train = X_train.join(Y_train, on=\"PassengerId\").drop(Y_train[\"PassengerId\"])\n",
        "\n",
        "# Unir los conjuntos de prueba\n",
        "test = X_test.join(Y_test, on=\"PassengerId\").drop(Y_test[\"PassengerId\"])\n",
        "\n",
        "test_data.show()\n",
        "train_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl4JVL-YqM5-",
        "outputId": "4109b96b-cfa2-4dd5-b214-736dc79d706e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+--------+-----------+-------------+\n",
            "|PassengerId|Survived|SexIndex|Fare_Scaled|Pclass_Scaled|\n",
            "+-----------+--------+--------+-----------+-------------+\n",
            "|          3|       1|     1.0|      0.015|          1.0|\n",
            "|          7|       0|     0.0|      0.101|          0.0|\n",
            "|          9|       1|     1.0|      0.022|          1.0|\n",
            "|         14|       0|     0.0|      0.061|          1.0|\n",
            "|         20|       1|     1.0|      0.014|          1.0|\n",
            "|         24|       1|     0.0|      0.069|          0.0|\n",
            "|         30|       0|     0.0|      0.015|          1.0|\n",
            "|         36|       0|     0.0|      0.101|          0.0|\n",
            "|         46|       0|     0.0|      0.016|          1.0|\n",
            "|         47|       0|     0.0|       0.03|          1.0|\n",
            "|         48|       1|     1.0|      0.015|          1.0|\n",
            "|         50|       0|     1.0|      0.035|          1.0|\n",
            "|         52|       0|     0.0|      0.015|          1.0|\n",
            "|         56|       1|     0.0|      0.069|          0.0|\n",
            "|         63|       0|     0.0|      0.163|          0.0|\n",
            "|         70|       0|     0.0|      0.017|          1.0|\n",
            "|         78|       0|     0.0|      0.016|          1.0|\n",
            "|        101|       0|     1.0|      0.015|          1.0|\n",
            "|        113|       0|     0.0|      0.016|          1.0|\n",
            "|        117|       0|     0.0|      0.015|          1.0|\n",
            "+-----------+--------+--------+-----------+-------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-----------+--------+--------+-----------+-------------+\n",
            "|PassengerId|Survived|SexIndex|Fare_Scaled|Pclass_Scaled|\n",
            "+-----------+--------+--------+-----------+-------------+\n",
            "|          1|       0|     0.0|      0.014|          1.0|\n",
            "|          2|       1|     1.0|      0.139|          0.0|\n",
            "|          4|       1|     1.0|      0.104|          0.0|\n",
            "|          5|       0|     0.0|      0.016|          1.0|\n",
            "|          6|       0|     0.0|      0.017|          1.0|\n",
            "|          8|       0|     0.0|      0.041|          1.0|\n",
            "|         10|       1|     1.0|      0.059|          0.5|\n",
            "|         11|       1|     1.0|      0.033|          1.0|\n",
            "|         12|       1|     1.0|      0.052|          0.0|\n",
            "|         13|       0|     0.0|      0.016|          1.0|\n",
            "|         15|       0|     1.0|      0.015|          1.0|\n",
            "|         16|       1|     1.0|      0.031|          0.5|\n",
            "|         17|       0|     0.0|      0.057|          1.0|\n",
            "|         18|       1|     0.0|      0.025|          0.5|\n",
            "|         19|       0|     1.0|      0.035|          1.0|\n",
            "|         21|       0|     0.0|      0.051|          0.5|\n",
            "|         22|       1|     0.0|      0.025|          0.5|\n",
            "|         23|       1|     1.0|      0.016|          1.0|\n",
            "|         25|       0|     1.0|      0.041|          1.0|\n",
            "|         26|       1|     1.0|      0.061|          1.0|\n",
            "+-----------+--------+--------+-----------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "# Crea una lista con los nombres de las columnas de características\n",
        "feature_columns = [col for col in X_train.columns if col != 'PassengerId'] # Exclude 'PassengerId'\n",
        "\n",
        "# Usa VectorAssembler para combinar las características en un solo vector\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "\n",
        "# Crea un DataFrame con la columna de características ensamblada\n",
        "train_data = assembler.transform(train)\n",
        "test_data = assembler.transform(test)\n"
      ],
      "metadata": {
        "id": "4DhjFY04vI8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regresión logística"
      ],
      "metadata": {
        "id": "Nj_YQ8V5HiZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "# Define el modelo de regresión logística\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"Survived\")\n",
        "\n",
        "# Entrena el modelo\n",
        "lr_model = lr.fit(train_data)"
      ],
      "metadata": {
        "id": "5Z9jsKEVvK-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realiza predicciones en el conjunto de prueba\n",
        "predictions = lr_model.transform(test_data)\n",
        "\n",
        "# Evalúa el rendimiento del modelo\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "# Define el evaluador\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"Survived\")\n",
        "\n",
        "# Calcula el área bajo la curva ROC\n",
        "roc_auc = evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})\n",
        "print(f\"Área bajo la curva ROC: {roc_auc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vx7J5fQJvNz7",
        "outputId": "3bcec48c-fb9f-4f21-9497-d90beca2e73c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Área bajo la curva ROC: 0.8652889399158057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar el resumen del modelo\n",
        "training_summary = lr_model.summary\n",
        "print(f\"Área bajo la curva ROC (entrenamiento): {training_summary.areaUnderROC}\")\n",
        "print(f\"Coeficientes del modelo: {lr_model.coefficients}\")\n",
        "print(f\"Intercepto del modelo: {lr_model.intercept}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SexRjn02vccL",
        "outputId": "36497b8a-5560-4d9e-d544-ebb46e434a37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Área bajo la curva ROC (entrenamiento): 0.829527118316927\n",
            "Coeficientes del modelo: [2.580580293330536,1.2921166719593264,-1.6301883048344652]\n",
            "Intercepto del modelo: -0.5888939238500771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, when\n",
        "\n",
        "# Calcula la matriz de confusión manualmente\n",
        "tp = predictions.filter((col(\"Survived\") == 1) & (col(\"prediction\") == 1)).count()\n",
        "tn = predictions.filter((col(\"Survived\") == 0) & (col(\"prediction\") == 0)).count()\n",
        "fp = predictions.filter((col(\"Survived\") == 0) & (col(\"prediction\") == 1)).count()\n",
        "fn = predictions.filter((col(\"Survived\") == 1) & (col(\"prediction\") == 0)).count()\n",
        "\n",
        "print(\"Matriz de confusión:\")\n",
        "print(f\"Verdaderos positivos (TP): {tp}\")\n",
        "print(f\"Verdaderos negativos (TN): {tn}\")\n",
        "print(f\"Falsos positivos (FP): {fp}\")\n",
        "print(f\"Falsos negativos (FN): {fn}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMOO-HCnvmhv",
        "outputId": "f21c95ca-29b0-4b3b-97ba-f16753dad6fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de confusión:\n",
            "Verdaderos positivos (TP): 46\n",
            "Verdaderos negativos (TN): 66\n",
            "Falsos positivos (FP): 12\n",
            "Falsos negativos (FN): 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "print(f\"Precisión del modelo: {accuracy}\")\n",
        "\n",
        "tpr = tp / (tp + fn)\n",
        "print(f\"Tasa de verdaderos positivos (TPR): {tpr}\")\n",
        "fpr = fp / (fp + tn)\n",
        "print(f\"Tasa de falsos positivos (FPR): {fpr}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFeZCYBW0OQB",
        "outputId": "8df4b138-3f83-4b52-beab-1304f41e65db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del modelo: 0.7724137931034483\n",
            "Tasa de verdaderos positivos (TPR): 0.6865671641791045\n",
            "Tasa de falsos positivos (FPR): 0.15384615384615385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest\n"
      ],
      "metadata": {
        "id": "qTnEigqp8tmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Modelo Random Forest\n",
        "rf = RandomForestClassifier(labelCol=\"Survived\", featuresCol=\"features\", numTrees=100)\n",
        "\n",
        "# Entrenar el modelo\n",
        "rf_model = rf.fit(train_data)\n",
        "\n",
        "# Hacer predicciones en el conjunto de prueba\n",
        "rf_predictions = rf_model.transform(test_data)\n",
        "\n",
        "# Evaluar el modelo de Random Forest\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "rf_accuracy = evaluator.evaluate(rf_predictions)\n",
        "\n",
        "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "rf_f1 = f1_evaluator.evaluate(rf_predictions)\n",
        "\n",
        "print(f\"Random Forest Accuracy: {rf_accuracy}\")\n",
        "print(f\"Random Forest F1 Score: {rf_f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUM1hd4S72Og",
        "outputId": "6e1ed57a-92b0-4de4-d73e-d5efd81862fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.8\n",
            "Random Forest F1 Score: 0.7969485060394151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM"
      ],
      "metadata": {
        "id": "8o8MmxAM9H0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LinearSVC\n",
        "# Modelo SVM lineal\n",
        "svm = LinearSVC(labelCol=\"Survived\", featuresCol=\"features\", maxIter=10)\n",
        "\n",
        "# Entrenar el modelo\n",
        "svm_model = svm.fit(train_data)\n",
        "\n",
        "# Hacer predicciones en el conjunto de prueba\n",
        "svm_predictions = svm_model.transform(test_data)\n",
        "\n",
        "# Evaluar el modelo de SVM\n",
        "svm_accuracy = evaluator.evaluate(svm_predictions)\n",
        "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "svm_f1 = f1_evaluator.evaluate(svm_predictions)\n",
        "\n",
        "\n",
        "print(f\"SVM Accuracy: {svm_accuracy}\")\n",
        "print(f\"SVM F1 Score: {svm_f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfFGzRQB9SSl",
        "outputId": "42c27bf2-be5a-4e35-b46f-6db3570048e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.7793103448275862\n",
            "SVM F1 Score: 0.7770588471795972\n"
          ]
        }
      ]
    }
  ]
}